env: camas

env_args:
  map_name: "supermarket"
  # Number of agents to use in the environment
  #     0: maximum number of agents
  #     Will return an error if number specifed is more than the maximum for the given map.
  agent_count: 0
  episode_limit: 0
  
  # Possible observation types: 
  #     global: [agent position, other agent positions.. ]
  #     context: [agent position, context of edges..  ]
  observation_type: "context"
  congestion: True
  dummy_actions: True

  # Divide reward by this factor before outputting
  reward_scaling_factor: 100

  # Mean and variance for Phase Type Distributions is calculated as:
  #     i*mean+1, var*(i+1)
  # where i is the congestion band and mean and var are set below.
  ptd_mean: 1.0
  ptd_var: 0.1

  # Rewards
  reward_type: "time-cost"
  goal_reward: 200
  time_multiplier: -4

  debug: False
  seed: Null  # NOTE this would be useful to implement

runner: "timelim"
gamma: 0.99
epsilon_start: 1.0
epsilon_anneal_time: 3000000

#buffer_size: 10000

test_greedy: True
test_nepisode: 32
test_interval: 20000 # all used to be 10000
log_interval: 20000
runner_log_interval: 20000
learner_log_interval: 20000

t_max: 15010000

save_model: True
save_model_interval: 500000
#checkpoint_path: "results/models/qmix__2022-03-23_18-35-08/" # Load a checkpoint from this path
